### **Архитектура приложения: Асинхронный конвейер обработки с очередями**

Это отказоустойчивый микросервис, построенный по принципу **"принять и обработать позже"**. Его основная задача — принимать большое количество запросов на генерацию описаний, не заставляя клиента ждать, и обрабатывать их в фоновом режиме с соблюдением внешних лимитов.



**Основные компоненты и их взаимодействие:**

1.  **API Gateway (FastAPI):**
    * Является **единой точкой входа** для всех HTTP-запросов (`app.py`).
    * Его задача — **быстро валидировать** запрос (подпись, доступность URL изображений) и немедленно **поставить задачу в очередь**, ответив клиенту `202 Accepted`. Он не занимается тяжелой обработкой.

2.  **Брокер сообщений (Redis):**
    * Выполняет роль **центральной системы очередей**.
    * Содержит две ключевые очереди: `vision_pending_queue` (для анализа изображений) и `translate_pending_queue` (для перевода текста).

3.  **Менеджер задач и Оркестратор (Celery):**
    * Это **"мозг" и "рабочие руки"** системы (`tasks.py`, `celery_app.py`).
    * **Оркестратор** (периодическая задача Celery) следит за лимитами OpenAI. Если есть свободные "слоты", он извлекает задачи из очереди Redis, формирует из них пачку (`batch`) и отправляет в OpenAI.
    * **Воркеры** (фоновые процессы Celery) выполняют задачи: отслеживают статус уже запущенных `batch`-задач, обрабатывают результаты и ставят новые задачи (например, на перевод).

4.  **Хранилище состояний (Redis):**
    * Помимо очередей, Redis используется для хранения **промежуточных результатов** (например, сгенерированный на английском текст) и **состояния** активных `batch`-задач. Это делает систему устойчивой к перезапускам.

5.  **Клиент OpenAI:**
    * Изолированный модуль (`openai_client.py`), который отвечает за все коммуникации с API OpenAI, включая загрузку файлов и создание `batch`-задач.

**Поток данных (Data Flow):**

Запрос клиента → **FastAPI** (валидация, ответ 202) → Задача ставится в **Celery** → Задача попадает в очередь `vision` в **Redis** → **Оркестратор (Celery)** забирает задачи из Redis и создает `batch` в OpenAI → Воркеры отслеживают `batch` → Результат (текст на EN) сохраняется в **Redis** → Новые задачи на перевод ставятся в очередь `translate` в **Redis** → **Оркестратор** создает `batch` на перевод → Результаты (переводы) сохраняются в **Redis** → Финальная задача отправляет результат на **Webhook** клиента.